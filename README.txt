#  Toxic Comment Classification (Russian)

Цель проекта — разработать систему, которая автоматически удаляет токсичные комментарии.  
Модель должна быть максимально чувствительной (высокий **recall**), но при этом не "банить всех подряд" (precision ≥ 0.95).

---
### Задача

Разработать бинарный классификатор, который:
- получает на вход текст комментария,
- предсказывает: **токсичный** или **нормальный**,
- минимизирует ложные срабатывания,
- при этом старается **максимально находить токсичные**.

---
### Используемый датасет

-  [Russian Language Toxic Comments](https://www.kaggle.com/datasets/blackmoon/russian-language-toxic-comments?utm_source=chatgpt.com)
---

### Предобработка текста

Для подготовки текста используется:
- токенизация (`word_tokenize`)
- удаление пунктуации
- удаление стоп-слов (`nltk`)
- стемминг (`SnowballStemmer` для русского)

---
## Векторизация

Используется `TfidfVectorizer` с кастомным токенизатором.  
Модель работает с TF-IDF признаками, построенными по токенам после стемминга.

---

###  Обучение модели

Базовая модель: `LogisticRegression`  
Проведён GridSearch по параметру `C`, использовалась кросс-валидация (`cv=3`).

Метрика для подбора: **F1-score** (баланс между точностью и полнотой)

---
###  Оценка модели

Оценка производилась с помощью:
- precision, recall, Precision-Recall кривая
- Подбор оптимального threshold

Модель достигла:
- precision ≈ 0.95
- recall ≈ 0.52

---

###  Возможные доработки

- Попробовать другие модели: `RandomForest`, `XGBoost`, `SGDClassifier`
- Векторизация: добавить `max_df`, `min_df`, `max_features`, `ngram_range`
- Лемматизация вместо стемминга
- Подготовка к деплою
- Подключение к FastAPI/Flask для API
